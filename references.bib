@article{goodman,
author = {Frank, Michael and Goodman, Noah},
year = {2012},
month = {05},
pages = {998},
title = {Predicting Pragmatic Reasoning in Language Games},
volume = {336},
journal = {Science (New York, N.Y.)},
doi = {10.1126/science.1218633}
}

@misc{wang2020mathematicaltheorycooperativecommunication,
      title={A mathematical theory of cooperative communication}, 
      author={Pei Wang and Junqi Wang and Pushpi Paranamana and Patrick Shafto},
      year={2020},
      eprint={1910.02822},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.02822}, 
}



@misc{gushchin2023buildingbridgeschrodingercontinuous,
      title={Building the Bridge of Schr\"odinger: A Continuous Entropic Optimal Transport Benchmark}, 
      author={Nikita Gushchin and Alexander Kolesov and Petr Mokrov and Polina Karpikova and Andrey Spiridonov and Evgeny Burnaev and Alexander Korotin},
      year={2023},
      eprint={2306.10161},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2306.10161}, 
}

@article{10.1214/aoms/1177703591,
author = {Richard Sinkhorn},
title = {{A Relationship Between Arbitrary Positive Matrices and Doubly Stochastic Matrices}},
volume = {35},
journal = {The Annals of Mathematical Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {876 -- 879},
year = {1964},
doi = {10.1214/aoms/1177703591},
URL = {https://doi.org/10.1214/aoms/1177703591}
}

@misc{léonard2013surveyschrodingerproblemconnections,
      title={A survey of the Schr\"odinger problem and some of its connections with optimal transport}, 
      author={Christian Léonard},
      year={2013},
      eprint={1308.0215},
      archivePrefix={arXiv},
      primaryClass={math.PR},
      url={https://arxiv.org/abs/1308.0215}, 
}

@article{pjm/1102992505,
author = {Paul Knopp and Richard Sinkhorn},
title = {{Concerning nonnegative matrices and doubly stochastic matrices.}},
volume = {21},
journal = {Pacific Journal of Mathematics},
number = {2},
publisher = {Pacific Journal of Mathematics, A Non-profit Corporation},
pages = {343 -- 348},
year = {1967},
}

@ARTICLE{6770983,
  author={Krupp, R. S.},
  journal={The Bell System Technical Journal}, 
  title={Properties of krulthof's Projection method}, 
  year={1979},
  volume={58},
  number={2},
  pages={517-538},
  keywords={},
  doi={10.1002/j.1538-7305.1979.tb02231.x}}

@inproceedings{Sinkhorn1967DiagonalET,
  title={Diagonal equivalence to matrices with prescribed row and column sums. II},
  author={Richard Sinkhorn},
  year={1967},
  url={https://api.semanticscholar.org/CorpusID:123068619}
}

@misc{idel2016reviewmatrixscalingsinkhorns,
      title={A review of matrix scaling and Sinkhorn's normal form for matrices and positive maps}, 
      author={Martin Idel},
      year={2016},
      eprint={1609.06349},
      archivePrefix={arXiv},
      primaryClass={math.RA},
      url={https://arxiv.org/abs/1609.06349}, 
}

@misc{baradat2023convergencesinkhornalgorithmschrodinger,
      title={Convergence of the Sinkhorn algorithm when the Schr\"odinger problem has no solution}, 
      author={Aymeric Baradat and Elias Ventre},
      year={2023},
      eprint={2207.02977},
      archivePrefix={arXiv},
      primaryClass={math.OC},
      url={https://arxiv.org/abs/2207.02977}, 
}



@incollection{bunt_computational_2017,
	title = {Computational Pragmatics},
	isbn = {978-0-19-969796-0},
	url = {https://doi.org/10.1093/oxfordhb/9780199697960.013.18},
	abstract = {This chapter presents a characterisation of the field of computational pragmatics, discusses some of the fundamental issues in the field, and provides a survey of recent developments. Central to computational pragmatics is the development and use of computational tools and models for studying the relations between utterances and their context of use. Essential for understanding these relations are the use of inference and the description of language use as actions inspired by the context, and intended to influence the context. The chapter therefore focuses on recent work in the use of inference for utterance interpretation and in dialogue modeling in terms of dialogue acts, viewed as context-changing actions. The chapter concludes with a survey of recent activities concerning the construction and use of resources in computational pragmatics, in particular annotation schemes, annotated corpora, and tools for corpus construction and use.},
	pages = {0},
	booktitle = {The Oxford Handbook of Pragmatics},
	publisher = {Oxford University Press},
	author = {Bunt, Harry},
	editor = {Huang, Yan},
	urldate = {2024-06-03},
	date = {2017-01-26},
	doi = {10.1093/oxfordhb/9780199697960.013.18},
	file = {Bunt - 2017 - Computational Pragmatics.pdf:C\:\\Users\\gabri\\Zotero\\storage\\T2CLYIST\\Bunt - 2017 - Computational Pragmatics.pdf:application/pdf},
}

@misc{cohn-gordon_lost_2019,
	title = {Lost in Machine Translation: A Method to Reduce Meaning Loss},
	url = {http://arxiv.org/abs/1902.09514},
	doi = {10.48550/arXiv.1902.09514},
	shorttitle = {Lost in Machine Translation},
	abstract = {A desideratum of high-quality translation systems is that they preserve meaning, in the sense that two sentences with different meanings should not translate to one and the same sentence in another language. However, state-of-the-art systems often fail in this regard, particularly in cases where the source and target languages partition the "meaning space" in different ways. For instance, "I cut my finger." and "I cut my finger off." describe different states of the world but are translated to French (by both Fairseq and Google Translate) as "Je me suis coupe le doigt.", which is ambiguous as to whether the finger is detached. More generally, translation systems are typically many-to-one (non-injective) functions from source to target language, which in many cases results in important distinctions in meaning being lost in translation. Building on Bayesian models of informative utterance production, we present a method to define a less ambiguous translation system in terms of an underlying pre-trained neural sequence-to-sequence model. This method increases injectivity, resulting in greater preservation of meaning as measured by improvement in cycle-consistency, without impeding translation quality (measured by {BLEU} score).},
	number = {{arXiv}:1902.09514},
	publisher = {{arXiv}},
	author = {Cohn-Gordon, Reuben and Goodman, Noah},
	urldate = {2024-06-03},
	date = {2019-04-22},
	eprinttype = {arxiv},
	eprint = {1902.09514 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Cohn-Gordon and Goodman - 2019 - Lost in Machine Translation A Method to Reduce Me.pdf:C\:\\Users\\gabri\\Zotero\\storage\\QEQL94JR\\Cohn-Gordon and Goodman - 2019 - Lost in Machine Translation A Method to Reduce Me.pdf:application/pdf},
}

@article{goodman_pragmatic_2016,
	title = {Pragmatic Language Interpretation as Probabilistic Inference},
	volume = {20},
	issn = {1364-6613, 1879-307X},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(16)30122-X},
	doi = {10.1016/j.tics.2016.08.005},
	pages = {818--829},
	number = {11},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Goodman, Noah D. and Frank, Michael C.},
	urldate = {2024-06-03},
	date = {2016-11-01},
	pmid = {27692852},
	note = {Publisher: Elsevier},
	file = {Goodman and Frank - 2016 - Pragmatic Language Interpretation as Probabilistic.pdf:C\:\\Users\\gabri\\Zotero\\storage\\Q34HCPBF\\Goodman and Frank - 2016 - Pragmatic Language Interpretation as Probabilistic.pdf:application/pdf},
}

@article{frank_predicting_2012,
	title = {Predicting Pragmatic Reasoning in Language Games},
	volume = {336},
	url = {https://www.science.org/doi/abs/10.1126/science.1218633},
	doi = {10.1126/science.1218633},
	abstract = {One of the most astonishing features of human language is its capacity to convey information efficiently in context. Many theories provide informal accounts of communicative inference, yet there have been few successes in making precise, quantitative predictions about pragmatic reasoning. We examined judgments about simple referential communication games, modeling behavior in these games by assuming that speakers attempt to be informative and that listeners use Bayesian inference to recover speakers’ intended referents. Our model provides a close, parameter-free fit to human judgments, suggesting that the use of information-theoretic tools to predict pragmatic reasoning may lead to more effective formal models of communication.},
	pages = {998--998},
	number = {6084},
	journaltitle = {Science},
	author = {Frank, Michael C. and Goodman, Noah D.},
	urldate = {2024-06-03},
	date = {2012-05-25},
	note = {Publisher: American Association for the Advancement of Science},
	file = {Frank and Goodman - 2012 - Predicting Pragmatic Reasoning in Language Games.pdf:C\:\\Users\\gabri\\Zotero\\storage\\7MBP5V5W\\Frank and Goodman - 2012 - Predicting Pragmatic Reasoning in Language Games.pdf:application/pdf},
}

@incollection{grice_logic_1975,
	title = {Logic and Conversation},
	url = {https://brill.com/display/book/edcoll/9789004368811/BP000003.xml},
	author = {Grice, H. P.},
	urldate = {2024-06-03},
	date = {1975-12-12},
	langid = {english},
	doi = {10.1163/9789004368811_003},
	note = {Section: Speech Acts},
	keywords = {Languages and Linguistics, Morphology \& Syntax, Semantics},
	file = {Grice - 1975 - Logic and Conversation.pdf:C\:\\Users\\gabri\\Zotero\\storage\\WH3ECN6U\\Grice - 1975 - Logic and Conversation.pdf:application/pdf},
}

@misc{cohn-gordon_pragmatically_2018,
	title = {Pragmatically Informative Image Captioning with Character-Level Inference},
	url = {http://arxiv.org/abs/1804.05417},
	doi = {10.48550/arXiv.1804.05417},
	abstract = {We combine a neural image captioner with a Rational Speech Acts ({RSA}) model to make a system that is pragmatically informative: its objective is to produce captions that are not merely true but also distinguish their inputs from similar images. Previous attempts to combine {RSA} with neural image captioning require an inference which normalizes over the entire set of possible utterances. This poses a serious problem of efficiency, previously solved by sampling a small subset of possible utterances. We instead solve this problem by implementing a version of {RSA} which operates at the level of characters ("a","b","c"...) during the unrolling of the caption. We find that the utterance-level effect of referential captions can be obtained with only character-level decisions. Finally, we introduce an automatic method for testing the performance of pragmatic speaker models, and show that our model outperforms a non-pragmatic baseline as well as a word-level {RSA} captioner.},
	number = {{arXiv}:1804.05417},
	publisher = {{arXiv}},
	author = {Cohn-Gordon, Reuben and Goodman, Noah and Potts, Christopher},
	urldate = {2024-06-03},
	date = {2018-05-10},
	eprinttype = {arxiv},
	eprint = {1804.05417 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\gabri\\Zotero\\storage\\XIZ4FQZE\\Cohn-Gordon et al. - 2018 - Pragmatically Informative Image Captioning with Ch.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\gabri\\Zotero\\storage\\97T7WL77\\1804.html:text/html},
}

@article{degen_rational_2023,
	title = {The Rational Speech Act Framework},
	volume = {9},
	issn = {2333-9683, 2333-9691},
	url = {https://www.annualreviews.org/content/journals/10.1146/annurev-linguistics-031220-010811},
	doi = {10.1146/annurev-linguistics-031220-010811},
	abstract = {The past decade has seen the rapid development of a new approach to pragmatics that attempts to integrate insights from formal and experimental semantics and pragmatics, psycholinguistics, and computational cognitive science in the study of meaning: probabilistic pragmatics. The most influential probabilistic approach to pragmatics is the Rational Speech Act ({RSA}) framework. In this review, I demonstrate the basic mechanics and commitments of {RSA} as well as some of its standard extensions, highlighting the key features that have led to its success in accounting for a wide variety of pragmatic phenomena. Fundamentally, it treats language as probabilistic, informativeness as gradient, alternatives as context-dependent, and subjective prior beliefs (world knowledge) as a crucial facet of interpretation. It also provides an integrated account of the link between production and interpretation. I highlight key challenges for {RSA}, which include scalability, the treatment of the boundedness of cognition, and the incremental and compositional nature of language.},
	pages = {519--540},
	issue = {Volume 9, 2023},
	journaltitle = {Annual Review of Linguistics},
	author = {Degen, Judith},
	urldate = {2024-06-03},
	date = {2023-01-17},
	langid = {french},
	note = {Publisher: Annual Reviews},
	file = {Full Text:C\:\\Users\\gabri\\Zotero\\storage\\PH9FET9V\\Degen - 2023 - The Rational Speech Act Framework.pdf:application/pdf;Snapshot:C\:\\Users\\gabri\\Zotero\\storage\\HUK8A2PW\\annurev-linguistics-031220-010811.html:text/html},
}

@article{inoue_ilp-based_2011,
	title = {{ILP}-based Reasoning for Weighted Abduction},
	abstract = {Abduction is widely used in the task of plan recognition, since it can be viewed as the task of ﬁnding the best explanation for a set of observations. The major drawback of abduction is its computational complexity. The task of abductive reasoning quickly becomes intractable as the background knowledge is increased. Recent efforts in the ﬁeld of computational linguistics have enriched computational resources for commonsense reasoning. The enriched knowledge base facilitates exploring practical plan recognition models in an open-domain. Therefore, it is essential to develop an efﬁcient framework for such large-scale processing. In this paper, we propose an efﬁcient implementation of Weighted abduction. Our framework transforms the problem of explanation ﬁnding in Weighted abduction into a linear programming problem. Our experiments showed that our approach efﬁciently solved problems of plan recognition and outperforms state-of-the-art tool for Weighted abduction.},
	author = {Inoue, Naoya and Inui, Kentaro},
	date = {2011},
	langid = {english},
	file = {Inoue and Inui - ILP-based Reasoning for Weighted Abduction.pdf:C\:\\Users\\gabri\\Zotero\\storage\\NIET67IH\\Inoue and Inui - ILP-based Reasoning for Weighted Abduction.pdf:application/pdf},
}

@online{noauthor_henry_2012,
	title = {Henry N700},
	url = {https://code.google.com/archive/p/henry-n700/},
	urldate = {2024-06-03},
	date = {2012},
	file = {Henry N700.pdf:C\:\\Users\\gabri\\Zotero\\storage\\NSM8GR3M\\Henry N700.pdf:application/pdf},
}

@incollection{inoue_weighted_2014,
	location = {Boston},
	title = {Weighted Abduction for Discourse Processing Based on Integer Linear Programming},
	isbn = {978-0-12-398532-3},
	url = {https://www.sciencedirect.com/science/article/pii/B9780123985323000026},
	abstract = {This chapter explores the logical framework called weighted abduction as applied to solving discourse-processing tasks. Weighted abduction incorporates a cost propagation mechanism allowing us to estimate the likelihood of the obtained abductive proofs. We use a tractable implementation of weighted abduction based on Integer Linear Programming and a large knowledge base generated automatically. We first perform an experiment on plan recognition using the dataset originally developed for Ng and Mooney’s system [39]. Then we apply our discourse processing pipeline for predicting whether one text fragment logically entails another one (Recognizing Textual Entailment task). The study we describe is the first attempt to apply tractable inference-based natural language processing on a large scale.},
	pages = {33--55},
	booktitle = {Plan, Activity, and Intent Recognition},
	publisher = {Morgan Kaufmann},
	author = {Inoue, Naoya and Ovchinnikova, Ekaterina and Inui, Kentaro and Hobbs, Jerry},
	editor = {Sukthankar, Gita and Geib, Christopher and Bui, Hung Hai and Pynadath, David V. and Goldman, Robert P.},
	urldate = {2024-06-03},
	date = {2014-01-01},
	doi = {10.1016/B978-0-12-398532-3.00002-6},
	keywords = {Integer Linear Programming, natural language understanding, planning, Recognizing Textual Entailment, weighted abduction},
	file = {Inoue et al. - 2014 - Chapter 2 - Weighted Abduction for Discourse Proce.pdf:C\:\\Users\\gabri\\Zotero\\storage\\SRS3LDD5\\Inoue et al. - 2014 - Chapter 2 - Weighted Abduction for Discourse Proce.pdf:application/pdf},
}

@misc{white_learning_2020,
	title = {Learning to refer informatively by amortizing pragmatic reasoning},
	url = {http://arxiv.org/abs/2006.00418},
	doi = {10.48550/arXiv.2006.00418},
	abstract = {A hallmark of human language is the ability to effectively and efficiently convey contextually relevant information. One theory for how humans reason about language is presented in the Rational Speech Acts ({RSA}) framework, which captures pragmatic phenomena via a process of recursive social reasoning (Goodman \& Frank, 2016). However, {RSA} represents ideal reasoning in an unconstrained setting. We explore the idea that speakers might learn to amortize the cost of {RSA} computation over time by directly optimizing for successful communication with an internal listener model. In simulations with grounded neural speakers and listeners across two communication game datasets representing synthetic and human-generated data, we find that our amortized model is able to quickly generate language that is effective and concise across a range of contexts, without the need for explicit pragmatic reasoning.},
	number = {{arXiv}:2006.00418},
	publisher = {{arXiv}},
	author = {White, Julia and Mu, Jesse and Goodman, Noah D.},
	urldate = {2024-06-04},
	date = {2020-05-30},
	eprinttype = {arxiv},
	eprint = {2006.00418 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\gabri\\Zotero\\storage\\8TTS7NN8\\White et al. - 2020 - Learning to refer informatively by amortizing prag.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\gabri\\Zotero\\storage\\CPUKYKLD\\2006.html:text/html},
}

@article{carenini_towards_2023,
	title = {Towards a Better Rational Speech Act Framework for Context-Aware Modeling of Metaphor Understanding},
	abstract = {Modeling language is a fundamental step for understanding human communication and improving human-computer interaction. The Rational Speech Act ({RSA}) model provides a flexible framework to pursue this objective by catching pragmatic reasoning. However, state-of-theart models still have limitations in dealing with context. We present a new {RSA} framework for metaphor understanding that accounts explicitly for the role of context by emphasizing the mutual shared information between the speaker and the listener in the estimation of the communicative goal. The model is tested extensively against 24 metaphors (with either intrinsic or emergent properties) and its predictions are compared to human data.},
	author = {Carenini, Gaia and Bischetti, Luca and Schaeken, Walter and Bambini, Valentina},
	date = {2023},
	langid = {english},
	file = {Carenini et al. - Towards a Better Rational Speech Act Framework for.pdf:C\:\\Users\\gabri\\Zotero\\storage\\V5WS6LHA\\Carenini et al. - Towards a Better Rational Speech Act Framework for.pdf:application/pdf},
}

@misc{frank_rational_2016,
	title = {Rational speech act models of pragmatic reasoning in reference games},
	url = {https://osf.io/f9y6b},
	doi = {10.31234/osf.io/f9y6b},
	abstract = {Human communication is almost always ambiguous, but it typically takes place in a context where this ambiguity can be resolved. A key part of this process of disambiguation comes from pragmatic reasoning about alternative messages that a speaker could have said in that context. Following previous work, we describe pragmatic inference as recursive reasoning – in which listeners reason about speakers and vice versa – using a “rational speech act” ({RSA}) model. We then systematically test the parameters and design decisions of this model through a series of ten experiments using one-shot reference-resolution games (N = 7,569). Such games present a valuable and tractable microcosm for studying broader questions about communication in context, and human behavior within them can be described using the {RSA} framework.},
	publisher = {{OSF}},
	author = {Frank, Michael C.},
	urldate = {2024-06-05},
	date = {2016-09-21},
	langid = {english},
	keywords = {Preprint, {PsyArXiv}},
	file = {Submitted Version:C\:\\Users\\gabri\\Zotero\\storage\\JMZVY72Z\\Frank - 2016 - Rational speech act models of pragmatic reasoning .pdf:application/pdf},
}

@article{degen_wonky_2015,
	title = {Wonky worlds: Listeners revise world knowledge when utterances are odd},
	abstract = {World knowledge enters into pragmatic utterance interpretation in complex ways, and may be defeasible in light of speakers’ utterances. Yet there is to date a surprising lack of systematic investigation into the role of world knowledge in pragmatic inference. In this paper, we show that a state-of-the-art model of pragmatic interpretation greatly overestimates the inﬂuence of world knowledge on the interpretation of utterances like Some of the marbles sank. We extend the model to capture the idea that the listener is uncertain about the background knowledge the speaker is bringing to the conversation. This extension greatly improves model predictions of listeners’ interpretation and also makes good qualitative predictions about listeners’ judgments of how ‘normal’ the world is in light of a speaker’s statement. Theoretical and methodological implications are discussed.},
	author = {Degen, Judith and Tessler, Michael Henry and Goodman, Noah D},
	date = {2015},
	langid = {english},
	file = {Degen et al. - Wonky worlds Listeners revise world knowledge whe.pdf:C\:\\Users\\gabri\\Zotero\\storage\\YLRELLXS\\Degen et al. - Wonky worlds Listeners revise world knowledge whe.pdf:application/pdf},
}

@article{bergen_pragmatic_2016,
	title = {Pragmatic reasoning through semantic inference},
	volume = {9},
	rights = {Copyright (c) 2016 Leon Bergen, Roger Levy, Noah Goodman},
	issn = {1937-8912},
	url = {https://semprag.org/index.php/sp/article/view/sp.9.20},
	doi = {10.3765/sp.9.20},
	abstract = {A number of recent proposals have used techniques from game theory and Bayesian cognitive science to formalize Gricean pragmatic reasoning (Frank \& Goodman, 2012; Franke, 2009; Goodman \& Stuhlmuller, 2013; Jager, 2012). We discuss two phenomena which pose a challenge to these accounts of pragmatics: M-implicatures (Horn, 1984) and embedded implicatures which violate Hurford’s constraint (Chierchia, Fox, \& Spector, 2012; Hurford, 1974). While techniques have been developed for deriving M-implicatures, Hurford-violating em- bedded implicatures pose a more fundamental challenge, because of basic limitations in the models’ architecture. In order to explain these phenomena, we propose a realignment of the division between semantic content and pragmatic content. Under this proposal, the semantic content of an utterance is not fixed independent of pragmatic inference; rather, pragmatic inference partially determines an utterance’s semantic content. We show how semantic inference can be realized as an extension to the Rational Speech Acts framework (Goodman \& Stuhlmuller, 2013). The addition of lexical uncertainty derives both M-implicatures and the relevant embedded implicatures, and preserves the derivations of more standard implicatures. We use this principle to explain a novel class of implicature, non-convex disjunctive implicatures, which have several theoretically interesting properties. In particular, these implicatures can be preserved in downward-entailing contexts in the absence of accenting, a property which is predicted by lexical uncertainty, but which violates prior generalizations in the literature (Fox \& Spector, in press; Horn, 1989).

{EARLY} {ACCESS} {VERSION}},
	pages = {ACCESS--ACCESS},
	journaltitle = {Semantics and Pragmatics},
	author = {Bergen, Leon and Levy, Roger and Goodman, Noah},
	urldate = {2024-06-05},
	date = {2016-05-10},
	langid = {english},
	keywords = {Bayesian modeling, Division of pragmatic labor, Embedded implicatures, Game theory, Hurford’s constraint, Pragmatics},
	file = {Full Text PDF:C\:\\Users\\gabri\\Zotero\\storage\\BG5EXN3N\\Bergen et al. - 2016 - Pragmatic reasoning through semantic inference.pdf:application/pdf},
}

@misc{zaslavsky_rate-distortion_2020,
	title = {A Rate-Distortion view of human pragmatic reasoning},
	url = {http://arxiv.org/abs/2005.06641},
        year = {2020},
	number = {{arXiv}:2005.06641},
	publisher = {{arXiv}},
	author = {Zaslavsky, Noga and Hu, Jennifer and Levy, Roger P.},
	urldate = {2024-06-07},
	date = {2020-05-13},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2005.06641 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Zaslavsky et al. - 2020 - A Rate-Distortion view of human pragmatic reasonin.pdf:C\:\\Users\\gabri\\Zotero\\storage\\WXDA4WIS\\Zaslavsky et al. - 2020 - A Rate-Distortion view of human pragmatic reasonin.pdf:application/pdf},
}

@misc{ruis_goldilocks_2023,
	title = {The Goldilocks of Pragmatic Understanding: Fine-Tuning Strategy Matters for Implicature Resolution by {LLMs}},
	url = {http://arxiv.org/abs/2210.14986},
	shorttitle = {The Goldilocks of Pragmatic Understanding},
	abstract = {Despite widespread use of {LLMs} as conversational agents, evaluations of performance fail to capture a crucial aspect of communication: interpreting language in context—incorporating its pragmatics. Humans interpret language using beliefs and prior knowledge about the world. For example, we intuitively understand the response “I wore gloves” to the question “Did you leave fingerprints?” as meaning “No”. To investigate whether {LLMs} have the ability to make this type of inference, known as an implicature, we design a simple task and evaluate four categories of widely used state-of-the-art models. We find that, despite only evaluating on utterances that require a binary inference (yes or no), models in three of these categories perform close to random. However, {LLMs} instruction-tuned at the example-level perform significantly better. These results suggest that certain fine-tuning strategies are far better at inducing pragmatic understanding in models. We present our findings as the starting point for further research into evaluating how {LLMs} interpret language in context and to drive the development of more pragmatic and useful models of human discourse.},
	number = {{arXiv}:2210.14986},
	publisher = {{arXiv}},
	author = {Ruis, Laura and Khan, Akbir and Biderman, Stella and Hooker, Sara and Rocktäschel, Tim and Grefenstette, Edward},
	urldate = {2024-06-17},
	date = {2023-12-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2210.14986 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Ruis et al. - 2023 - The Goldilocks of Pragmatic Understanding Fine-Tu.pdf:C\:\\Users\\gabri\\Zotero\\storage\\M2F7ZY2J\\Ruis et al. - 2023 - The Goldilocks of Pragmatic Understanding Fine-Tu.pdf:application/pdf},
}

@book{noauthor_elements_1999,
	title = {Elements of Information Theory},
	date = {1999},
	file = {ch1 - introduction and preview.pdf:C\:\\Users\\gabri\\Zotero\\storage\\HIBQDWB9\\ch1 - introduction and preview.pdf:application/pdf;ch2 - entropy, relative entropy, and mutual information.pdf:C\:\\Users\\gabri\\Zotero\\storage\\2LFKAB4I\\ch2 - entropy, relative entropy, and mutual information.pdf:application/pdf;ch3 - asymptotic equipartition property.pdf:C\:\\Users\\gabri\\Zotero\\storage\\ZLXKMLMH\\ch3 - asymptotic equipartition property.pdf:application/pdf;ch4 - entropy rates of a stochastic process.pdf:C\:\\Users\\gabri\\Zotero\\storage\\59FMQA9S\\ch4 - entropy rates of a stochastic process.pdf:application/pdf;ch5 - data compression.pdf:C\:\\Users\\gabri\\Zotero\\storage\\TVHCEXTG\\ch5 - data compression.pdf:application/pdf;ch10 - rate distortion theory.pdf:C\:\\Users\\gabri\\Zotero\\storage\\8LZGY6Y7\\ch10 - rate distortion theory.pdf:application/pdf},
}

@inproceedings{haarnoja_soft_2018,
	title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
	url = {https://proceedings.mlr.press/v80/haarnoja18b.html},
	shorttitle = {Soft Actor-Critic},
	abstract = {Model-free deep reinforcement learning ({RL}) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep {RL} algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep {RL} methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.},
	eventtitle = {International Conference on Machine Learning},
	pages = {1861--1870},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	urldate = {2024-06-19},
	date = {2018-07-03},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:C\:\\Users\\gabri\\Zotero\\storage\\ZJ9LKQUU\\Haarnoja et al. - 2018 - Soft Actor-Critic Off-Policy Maximum Entropy Deep.pdf:application/pdf;Supplementary PDF:C\:\\Users\\gabri\\Zotero\\storage\\2NTPCDNR\\Haarnoja et al. - 2018 - Soft Actor-Critic Off-Policy Maximum Entropy Deep.pdf:application/pdf},
}

@article{ohmer_reinforcement_2020,
	title = {Reinforcement of Semantic Representations in Pragmatic Agents Leads to the Emergence of a Mutual Exclusivity Bias},
	author = {Ohmer, Xenia and Konig, Peter and Franke, Michael},
	date = {2020},
	langid = {english},
	file = {Ohmer et al. - Reinforcement of Semantic Representations in Pragm.pdf:C\:\\Users\\gabri\\Zotero\\storage\\LGHC6ABC\\Ohmer et al. - Reinforcement of Semantic Representations in Pragm.pdf:application/pdf},
}

@article{menendez_entropy_1997,
	title = {Entropy Differential Metric},
	author = {Menendez, M. L. and Morales, D. and Pardo, L.},
	date = {1997},
	file = {Menendez - Entropy Differential Metric:C\:\\Users\\gabri\\Zotero\\storage\\F9NITG6M\\_.pdf:application/pdf},
}

@article{salicru_asymptotic_1993,
	title = {Asymptotic distribution of (h, φ)-entropies},
	volume = {22},
	issn = {0361-0926},
	url = {https://doi.org/10.1080/03610929308831131},
	doi = {10.1080/03610929308831131},
	abstract = {In this paper, (h,φ)-entropies are presented as a generalization of φ-entropies, Havrda-Charvat entropies and the Renyi entropy among others. For this functional, asymptotic distribution for simple random sampling and stratified .sampling with proportional affixing is obtained.},
	pages = {2015--2031},
	number = {7},
	journaltitle = {Communications in Statistics - Theory and Methods},
	author = {Salicru, M. and Menendez, M.L. and Morales, D. and Pardo, L.},
	urldate = {2024-06-26},
	date = {1993-01-01},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/03610929308831131},
	keywords = {asymptotic distribution, φ-entropies},
	file = {Salicru et al. - 1993 - Asymptotic distribution of (h, φ)-entropies.pdf:C\:\\Users\\gabri\\Zotero\\storage\\D38QX4XU\\Salicru et al. - 1993 - Asymptotic distribution of (h, φ)-entropies.pdf:application/pdf},
}

@article{bosyk_family_2016,
	title = {A family of generalized quantum entropies: definition and properties},
	volume = {15},
	issn = {1573-1332},
	url = {https://doi.org/10.1007/s11128-016-1329-5},
	doi = {10.1007/s11128-016-1329-5},
	shorttitle = {A family of generalized quantum entropies},
	abstract = {We present a quantum version of the generalized \$\$(h,{\textbackslash}phi )\$\$-entropies, introduced by Salicrú et al. for the study of classical probability distributions. We establish their basic properties and show that already known quantum entropies such as von Neumann, and quantum versions of Rényi, Tsallis, and unified entropies, constitute particular classes of the present general quantum Salicrú form. We exhibit that majorization plays a key role in explaining most of their common features. We give a characterization of the quantum \$\$(h,{\textbackslash}phi )\$\$-entropies under the action of quantum operations and study their properties for composite systems. We apply these generalized entropies to the problem of detection of quantum entanglement and introduce a discussion on possible generalized conditional entropies as well.},
	pages = {3393--3420},
	number = {8},
	journaltitle = {Quantum Information Processing},
	shortjournal = {Quantum Inf Process},
	author = {Bosyk, G. M. and Zozor, S. and Holik, F. and Portesi, M. and Lamberti, P. W.},
	urldate = {2024-06-26},
	date = {2016-08-01},
	langid = {english},
	keywords = {Entanglement detection, Majorization relation, Quantum entropies},
	file = {Full Text PDF:C\:\\Users\\gabri\\Zotero\\storage\\Z2SCRBRQ\\Bosyk et al. - 2016 - A family of generalized quantum entropies definit.pdf:application/pdf},
}

@misc{monroe_learning_2015,
	title = {Learning in the Rational Speech Acts Model},
	url = {http://arxiv.org/abs/1510.06807},
	doi = {10.48550/arXiv.1510.06807},
	abstract = {The Rational Speech Acts ({RSA}) model treats language use as a recursive process in which probabilistic speaker and listener agents reason about each other's intentions to enrich the literal semantics of their language along broadly Gricean lines. {RSA} has been shown to capture many kinds of conversational implicature, but it has been criticized as an unrealistic model of speakers, and it has so far required the manual specification of a semantic lexicon, preventing its use in natural language processing applications that learn lexical knowledge from data. We address these concerns by showing how to define and optimize a trained statistical classifier that uses the intermediate agents of {RSA} as hidden layers of representation forming a non-linear activation function. This treatment opens up new application domains and new possibilities for learning effectively from data. We validate the model on a referential expression generation task, showing that the best performance is achieved by incorporating features approximating well-established insights about natural language generation into {RSA}.},
	number = {{arXiv}:1510.06807},
	publisher = {{arXiv}},
	author = {Monroe, Will and Potts, Christopher},
	urldate = {2024-06-28},
	date = {2015-10-22},
	eprinttype = {arxiv},
	eprint = {1510.06807 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\gabri\\Zotero\\storage\\5QZBK6BS\\Monroe and Potts - 2015 - Learning in the Rational Speech Acts Model.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\gabri\\Zotero\\storage\\XKFWJC34\\1510.html:text/html},
}

@inproceedings{haarnoja_reinforcement_2017,
	title = {Reinforcement Learning with Deep Energy-Based Policies},
	url = {https://proceedings.mlr.press/v70/haarnoja17a.html},
	abstract = {We propose a method for learning expressive energy-based policies for continuous states and actions, which has been feasible only in tabular domains before. We apply our method to learning maximum entropy policies, resulting into a new algorithm, called soft Q-learning, that expresses the optimal policy via a Boltzmann distribution. We use the recently proposed amortized Stein variational gradient descent to learn a stochastic sampling network that approximates samples from this distribution. The benefits of the proposed algorithm include improved exploration and compositionality that allows transferring skills between tasks, which we confirm in simulated experiments with swimming and walking robots. We also draw a connection to actor-critic methods, which can be viewed performing approximate inference on the corresponding energy-based model.},
	eventtitle = {International Conference on Machine Learning},
	pages = {1352--1361},
	booktitle = {Proceedings of the 34th International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
	urldate = {2024-07-03},
	date = {2017-07-17},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:C\:\\Users\\gabri\\Zotero\\storage\\QZSB639V\\Haarnoja et al. - 2017 - Reinforcement Learning with Deep Energy-Based Poli.pdf:application/pdf;Supplementary PDF:C\:\\Users\\gabri\\Zotero\\storage\\P37K83B6\\Haarnoja et al. - 2017 - Reinforcement Learning with Deep Energy-Based Poli.pdf:application/pdf},
}

@article{shannon_mathematical_1948,
	title = {A mathematical theory of communication},
	volume = {27},
	issn = {0005-8580},
	url = {https://ieeexplore.ieee.org/abstract/document/6773024},
	doi = {10.1002/j.1538-7305.1948.tb01338.x},
	abstract = {The recent development of various methods of modulation such as {PCM} and {PPM} which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist1 and Hartley2 on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.},
	pages = {379--423},
	number = {3},
	journaltitle = {The Bell System Technical Journal},
	author = {Shannon, C. E.},
	urldate = {2024-07-03},
	date = {1948-07},
	note = {Conference Name: The Bell System Technical Journal},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\gabri\\Zotero\\storage\\CDWHRVHS\\6773024.html:text/html},
}

@inproceedings{toussaint_robot_2009,
	location = {New York, {NY}, {USA}},
	title = {Robot trajectory optimization using approximate inference},
	isbn = {978-1-60558-516-1},
	url = {https://doi.org/10.1145/1553374.1553508},
	doi = {10.1145/1553374.1553508},
	series = {{ICML} '09},
	abstract = {The general stochastic optimal control ({SOC}) problem in robotics scenarios is often too complex to be solved exactly and in near real time. A classical approximate solution is to first compute an optimal (deterministic) trajectory and then solve a local linear-quadratic-gaussian ({LQG}) perturbation model to handle the system stochasticity. We present a new algorithm for this approach which improves upon previous algorithms like {iLQG}. We consider a probabilistic model for which the maximum likelihood ({ML}) trajectory coincides with the optimal trajectory and which, in the {LQG} case, reproduces the classical {SOC} solution. The algorithm then utilizes approximate inference methods (similar to expectation propagation) that efficiently generalize to non-{LQG} systems. We demonstrate the algorithm on a simulated 39-{DoF} humanoid robot.},
	pages = {1049--1056},
	booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
	publisher = {Association for Computing Machinery},
	author = {Toussaint, Marc},
	urldate = {2024-07-03},
	date = {2009},
}

@thesis{ziebart_modeling_2010,
	location = {United States -- Pennsylvania},
	title = {Modeling Purposeful Adaptive Behavior with the Principle of Maximum Causal Entropy},
	rights = {Database copyright {ProQuest} {LLC}; {ProQuest} does not claim copyright in the individual underlying works.},
	url = {https://www.proquest.com/docview/845728212/abstract/DF8A34664341497FPQ/1},
	abstract = {Predicting human behavior from a small amount of training examples is a challenging machine learning problem. In this thesis, we introduce the principle of maximum causal entropy, a general technique for applying information theory to decision-theoretic, game-theoretic, and control settings where relevant information is sequentially revealed over time. This approach guarantees decision-theoretic performance by matching purposeful measures of behavior (Abbeel \& Ng, 2004), and/or enforces game-theoretic rationality constraints (Aumann, 1974), while otherwise being as uncertain as possible, which minimizes worst-case predictive log-loss (Grünwald \& Dawid, 2003).
We derive probabilistic models for decision, control, and multi-player game settings using this approach. We then develop corresponding algorithms for efficient inference that include relaxations of the Bellman equation (Bellman, 1957), and simple learning algorithms based on convex optimization. We apply the models and algorithms to a number of behavior prediction tasks. Specifically, we present empirical evaluations of the approach in the domains of vehicle route preference modeling using over 100,000 miles of collected taxi driving data, pedestrian motion modeling from weeks of indoor movement data, and robust prediction of game play in stochastic multi-player games.},
	pagetotal = {216},
	institution = {Carnegie Mellon University},
	type = {phdthesis},
	author = {Ziebart, Brian D.},
	urldate = {2024-07-03},
	date = {2010},
	note = {{ISBN}: 9781124414218},
	keywords = {Machine learning, Adaptive behavior, Applied sciences, Maximum entropy},
	file = {Full Text PDF:C\:\\Users\\gabri\\Zotero\\storage\\TV7BV9KK\\Ziebart - Modeling Purposeful Adaptive Behavior with the Pri.pdf:application/pdf},
}

@article{ziebart_maximum_2008,
	title = {Maximum Entropy Inverse Reinforcement Learning},
	abstract = {Recent research has shown the beneﬁt of framing problems of imitation learning as solutions to Markov Decision Problems. This approach reduces learning to the problem of recovering a utility function that makes the behavior induced by a near-optimal policy closely mimic demonstrated behavior. In this work, we develop a probabilistic approach based on the principle of maximum entropy. Our approach provides a well-deﬁned, globally normalized distribution over decision sequences, while providing the same performance guarantees as existing methods.},
	author = {Ziebart, Brian D and Maas, Andrew and Bagnell, J Andrew and Dey, Anind K},
	date = {2008},
	langid = {english},
	file = {Ziebart et al. - Maximum Entropy Inverse Reinforcement Learning.pdf:C\:\\Users\\gabri\\Zotero\\storage\\DDEULB6S\\Ziebart et al. - Maximum Entropy Inverse Reinforcement Learning.pdf:application/pdf},
}

@book{lewis_convention_1969,
	title = {Convention: A Philosophical Study},
	isbn = {978-0-470-69296-7},
	shorttitle = {Convention},
	abstract = {Convention was immediately recognized as a major contribution to the subject and its significance has remained undiminished since its first publication in 1969. Lewis analyzes social conventions as regularities in the resolution of recurring coordination problems-situations characterized by interdependent decision processes in which common interests are at stake. Conventions are contrasted with other kinds of regularity, and conventions governing systems of communication are given special attention.},
	pagetotal = {229},
	publisher = {John Wiley \& Sons},
	author = {Lewis, David},
	date = {1969},
	langid = {english},
	note = {Google-Books-{ID}: {GgCkLtTqBsMC}},
	keywords = {Philosophy / General, Philosophy / History \& Surveys / General},
}

@incollection{goos_notes_2002,
	location = {Berlin, Heidelberg},
	title = {Some Notes on Alternating Optimization},
	volume = {2275},
	isbn = {978-3-540-43150-3 978-3-540-45631-5},
	url = {http://link.springer.com/10.1007/3-540-45631-7_39},
	pages = {288--300},
	booktitle = {Advances in Soft Computing — {AFSS} 2002},
	publisher = {Springer Berlin Heidelberg},
	author = {Bezdek, James C. and Hathaway, Richard J.},
	editor = {Pal, Nikhil R. and Sugeno, Michio},
	editorb = {Goos, G. and Hartmanis, J. and Van Leeuwen, J.},
	editorbtype = {redactor},
	urldate = {2024-07-04},
	date = {2002},
	langid = {english},
	doi = {10.1007/3-540-45631-7_39},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Bezdek and Hathaway - 2002 - Some Notes on Alternating Optimization.pdf:C\:\\Users\\gabri\\Zotero\\storage\\6ZT3HSZP\\Bezdek and Hathaway - 2002 - Some Notes on Alternating Optimization.pdf:application/pdf},
}

@article{miller_global_1996,
	title = {A global optimization technique for statistical classifier design},
	volume = {44},
	issn = {1941-0476},
	url = {https://ieeexplore.ieee.org/document/553484/?arnumber=553484},
	doi = {10.1109/78.553484},
	abstract = {A global optimization method is introduced that minimize the rate of misclassification. We first derive the theoretical basis for the method, on which we base the development of a novel design algorithm and demonstrate its effectiveness and superior performance in the design of practical classifiers for some of the most popular structures currently in use. The method, grounded in ideas from statistical physics and information theory, extends the deterministic annealing approach for optimization, both to incorporate structural constraints on data assignments to classes and to minimize the probability of error as the cost objective. During the design, data are assigned to classes in probability so as to minimize the expected classification error given a specified level of randomness, as measured by Shannon's entropy. The constrained optimization is equivalent to a free-energy minimization, motivating a deterministic annealing approach in which the entropy and expected misclassification cost are reduced with the temperature while enforcing the classifier's structure. In the limit, a hard classifier is obtained. This approach is applicable to a variety of classifier structures, including the widely used prototype-based, radial basis function, and multilayer perceptron classifiers. The method is compared with learning vector quantization, back propagation ({BP}), several radial basis function design techniques, as well as with paradigms for more directly optimizing all these structures to minimize probability of error. The annealing method achieves significant performance gains over other design methods on a number of benchmark examples from the literature, while often retaining design complexity comparable with or only moderately greater than that of strict descent methods. Substantial gains, both inside and outside the training set, are achieved for complicated examples involving high-dimensional data and large class overlap.},
	pages = {3108--3122},
	number = {12},
	journaltitle = {{IEEE} Transactions on Signal Processing},
	author = {Miller, D. and Rao, A.V. and Rose, K. and Gersho, A.},
	urldate = {2024-07-08},
	date = {1996-12},
	note = {Conference Name: {IEEE} Transactions on Signal Processing},
	keywords = {Algorithm design and analysis, Annealing, Constraint optimization, Cost function, Design optimization, Entropy, Information theory, Optimization methods, Physics, Probability},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\gabri\\Zotero\\storage\\27W3CQ48\\553484.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\gabri\\Zotero\\storage\\DFHLWY9U\\Miller et al. - 1996 - A global optimization technique for statistical cl.pdf:application/pdf},
}

@article{jaynes_information_1957,
	title = {Information Theory and Statistical Mechanics},
	volume = {106},
	url = {https://link.aps.org/doi/10.1103/PhysRev.106.620},
	doi = {10.1103/PhysRev.106.620},
	abstract = {Information theory provides a constructive criterion for setting up probability distributions on the basis of partial knowledge, and leads to a type of statistical inference which is called the maximum-entropy estimate. It is the least biased estimate possible on the given information; i.e., it is maximally noncommittal with regard to missing information. If one considers statistical mechanics as a form of statistical inference rather than as a physical theory, it is found that the usual computational rules, starting with the determination of the partition function, are an immediate consequence of the maximum-entropy principle. In the resulting "subjective statistical mechanics," the usual rules are thus justified independently of any physical argument, and in particular independently of experimental verification; whether or not the results agree with experiment, they still represent the best estimates that could have been made on the basis of the information available.},
	pages = {620--630},
	number = {4},
	journaltitle = {Physical Review},
	shortjournal = {Phys. Rev.},
	author = {Jaynes, E. T.},
	urldate = {2024-07-08},
	date = {1957-05-15},
	note = {Publisher: American Physical Society},
	file = {APS Snapshot:C\:\\Users\\gabri\\Zotero\\storage\\5MQCMW6C\\PhysRev.106.html:text/html},
}

@misc{cuturi2013sinkhorndistanceslightspeedcomputation,
      title={Sinkhorn Distances: Lightspeed Computation of Optimal Transportation Distances}, 
      author={Marco Cuturi},
      year={2013},
      eprint={1306.0895},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1306.0895}, 
}

@article{Csiszar_1984,
author = {Csiszar, Imre and Tusnády, Gábor},
year = {1984},
month = {01},
pages = {},
title = {Information geometry and alternating minimization procedures},
volume = {1},
journal = {Stat Decis}
}